{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/Tf1GHKkx5hyc4GCItUWl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import google.generativeai as genai\n","import pandas as pd\n","import json\n","import os\n","import time\n","import sys\n","\n","# --- File Configuration ---\n","# We will now use a progress file to track our state.\n","INPUT_FILE = \"clinton_emails.json\"\n","OUTPUT_JSON_FILE = \"clinton_analysis_results.json\"\n","PROGRESS_FILE = \"clinton_analysis_progress.txt\"\n","\n","\n","def configure_api_and_test():\n","    \"\"\"\n","    Configures the genai API key from Colab Secrets or env variables\n","    and runs a simple test prompt to confirm it's working.\n","    \"\"\"\n","    API_KEY = None\n","    try:\n","        # Check if running in Google Colab and get the key from Colab's \"Secrets\"\n","        import google.colab.userdata\n","        API_KEY = google.colab.userdata.get('GEMINI_API_KEY')\n","        if not API_KEY:\n","            print(\"=\"*50)\n","            print(\"ERROR: 'GEMINI_API_KEY' not found in Colab Secrets.\")\n","            print(\"Please click the 'Key' (ðŸ”‘) icon in the left sidebar and add a new secret named 'GEMINI_API_KEY'.\")\n","            print(\"=\"*50)\n","            sys.exit(1)\n","        print(\"Successfully loaded API key from Colab Secrets.\")\n","\n","    except ImportError:\n","        # Not in Colab, fall back to standard environment variables\n","        try:\n","            API_KEY = os.environ[\"GEMINI_API_KEY\"]\n","            print(\"Successfully loaded API key from environment variable.\")\n","        except KeyError:\n","            print(\"=\"*50)\n","            print(\"ERROR: 'GEMINI_API_KEY' not found in environment variables.\")\n","            print(\"If not in Colab, please set the environment variable (e.g., 'export GEMINI_API_KEY=YOUR_KEY')\")\n","            print(\"=\"*50)\n","            sys.exit(1)\n","    except Exception as e:\n","        print(f\"Error loading API key: {e}\")\n","        sys.exit(1)\n","\n","    # Configure the API\n","    try:\n","        genai.configure(api_key=API_KEY)\n","    except Exception as e:\n","        print(f\"Error configuring Generative AI: {e}\")\n","        sys.exit(1)\n","\n","\n","\n","# --- AI Prompt Engineering ---\n","\n","# This SYSTEM_PROMPT defines the AI's role.\n","SYSTEM_PROMPT = \"\"\"\n","You are an AI assistant specializing in the analysis of government and diplomatic correspondence.\n","Your task is to analyze the text of a single email (which includes headers, body, and metadata) and extract two distinct categories of features:\n","1.  **Privacy Features**: Information that must be protected, identified, or redacted.\n","2.  **Utility Features**: The core, non-sensitive insights or purpose of the communication.\n","\"\"\"\n","\n","# This USER_PROMPT_TEMPLATE is the detailed instruction for *each* email.\n","# It is tailored specifically to the clinton_emails.json dataset.\n","USER_PROMPT_TEMPLATE = \"\"\"\n","Analyze the following email data (which includes metadata and the full body) and provide the output as a single, minified JSON object.\n","Use \"N/A\" if a specific feature is not found.\n","\n","---\n","### **FEATURE DEFINITIONS**\n","---\n","\n","#### 1. Privacy Features (Data to Protect/Identify)\n","* `Name`: Full names of people (e.g., \"Hillary Clinton\", \"Lanny Davis\").\n","* `Email Address`: All email addresses (e.g., \"hrod17@clintonemail.com\").\n","* `Employment Details`: Specific job titles linked to individuals (e.g., \"Special counsel to President Bill Clinton\").\n","* `Private Organization`: Names of private firms or non-governmental entities (e.g., \"Lanny J. Davis & Associates LLC\").\n","* `Personal URL`: Specific, non-public URLs.\n","* `Classification Marking`: Security headers (e.g., \"UNCLASSIFIED\", \"RELEASE IN PART\", \"CONFIDENTIAL\").\n","* `Redaction Code`: Exemption codes replacing text (e.g., \"B6\").\n","* `Case/Document Number`: Legal/archival identifiers (e.g., \"Case No. F-2014-20439\", \"Doc No. C05775652\").\n","* `Sender-Recipient Pair`: The primary sender and recipient as a string (e.g., \"Hillary Clinton -> Jake Sullivan\").\n","* `Timestamp`: The primary date and time of the email (e.g., \"2010-06-09 04:06\").\n","\n","#### 2. Utility Features (Valuable Insights to Extract)\n","* `Topic`: The core subject or theme in a few words (e.g., \"Gaza flotilla incident op-ed\", \"Memo on Colombia\", \"Greek debt crisis\").\n","* `Summary`: A brief, 1-2 sentence non-private summary of the email's content.\n","* `Key Entities (Non-PII)`: Public figures, governments, or public organizations *being discussed* (e.g., \"Turkish PM Erdogan\", \"Israel\", \"Washington Post\").\n","* `Intent/Stance`: The purpose of the email (e.g., \"Action-Required\", \"Forwarding\", \"Persuasive\", \"Informational\").\n","* `Action Item`: Any specific, direct request or task (e.g., \"Pls read and discuss\", \"Pls print 2 copies\").\n","\n","---\n","### **EXAMPLE**\n","---\n","**Example Input:**\n","Email Metadata:\n","From: Hillary Clinton\n","To: Jake Sullivan\n","Date: 2010-06-09 04:06\n","Subject: TO TURKISH PM ERDOGAN: TIME TO CONSIDER ALL THE FACTS\n","\n","Email Body:\n","UNCLASSIFIED U.S. Department of State Case No. F-2014-20439 Doc No. C05775652...RELEASE IN PART B6...From: H <hrod17@clintonemail.com>...To: 'sullivanjj@state.gov'...Pls read and discuss...Original Message...From: Lanny Davis...Subject: To Turkish PM Erdogan: Time to Consider all the Facts...[Op-ed text follows]...Lanny J. Davis...Special counsel to President Bill Clinton...\n","\n","**Example Output JSON:**\n","{{\"Name\": \"Hillary Clinton, Jake Sullivan, Lanny Davis, Recep Tayyip Erdogan\", \"Email Address\": \"hrod17@clintonemail.com, sullivanjj@state.gov\", \"Employment Details\": \"Special counsel to President Bill Clinton\", \"Private Organization\": \"Lanny J. Davis & Associates LLC\", \"Personal URL\": \"http://community.icontact.com/p/wwwlannydavis\", \"Classification Marking\": \"UNCLASSIFIED, RELEASE IN PART\", \"Redaction Code\": \"B6\", \"Case/Document Number\": \"Case No. F-2014-20439, Doc No. C05775652\", \"Sender-Recipient Pair\": \"Hillary Clinton -> Jake Sullivan\", \"Timestamp\": \"2010-06-09 04:06\", \"Topic\": \"Op-ed on Gaza flotilla incident and Turkish-Israeli relations\", \"Summary\": \"A forwarded op-ed from Lanny Davis arguing that Turkish PM Erdogan should consider all facts regarding the Gaza flotilla incident before criticizing Israel, drawing parallels to Turkey's own history.\", \"Key Entities (Non-PII)\": \"Turkish PM Erdogan, Israel, Turkey, Washington Post\", \"Intent/Stance\": \"Action-Required, Forwarding, Persuasive\", \"Action Item\": \"Pls read and discuss.\"}}\n","\n","---\n","### **EMAIL TO ANALYZE**\n","---\n","{email_context}\n","\"\"\"\n","\n","def analyze_single_email(email_obj):\n","    \"\"\"\n","    Analyzes a single email object using the Gemini API.\n","    \"\"\"\n","    email_body = email_obj.get('body')\n","    email_id = email_obj.get('email_id', 'N/A')\n","\n","    if not email_body:\n","        print(f\"  > Skipped email_id: {email_id} (no body text)\")\n","        return None\n","\n","    # --- PROMPT SIZE FIX ---\n","    # Instead of dumping the *entire* JSON object, we build a clean\n","    # context string. This is *much* smaller and avoids token limits.\n","    context_string = f\"\"\"\n","    Email Metadata:\n","    From: {email_obj.get('from', 'N/A')}\n","    To: {email_obj.get('to', 'N/A')}\n","    Date: {email_obj.get('date', 'N/A')}\n","    Subject: {email_obj.get('subject', 'N/A')}\n","\n","    Email Body:\n","    {email_body}\n","    \"\"\"\n","\n","    print(f\"  > Analyzing email_id: {email_id}...\")\n","\n","    model = genai.GenerativeModel(\n","        model_name='gemini-2.5-flash',\n","        system_instruction=SYSTEM_PROMPT\n","    )\n","\n","    full_prompt = USER_PROMPT_TEMPLATE.format(email_context=context_string)\n","\n","    try:\n","        response = model.generate_content(full_prompt)\n","        response_text = response.text.strip()\n","\n","        if response_text.startswith(\"```json\"):\n","            response_text = response_text[7:-3].strip()\n","\n","        json_object = json.loads(response_text)\n","        json_object['original_email_id'] = email_id\n","        json_object['original_text'] = email_body # Added original body text post-analysis\n","\n","        print(f\"  > Success for email_id: {email_id}\")\n","        return json_object\n","\n","    except json.JSONDecodeError:\n","        print(f\"  > FAILED to decode JSON for email_id: {email_id}\")\n","        print(f\"  > Raw response: {response_text}\")\n","        return None\n","    except Exception as e:\n","        print(f\"  > ERROR during API call for email_id: {email_id}: {e}\")\n","        # This will catch API errors, token limits, quota issues, etc.\n","        # Re-raise the exception to trigger the graceful stop\n","        raise e\n","\n","def load_existing_results(json_path):\n","    \"\"\"Loads existing analysis results from the JSON file if it exists.\"\"\"\n","    if not os.path.exists(json_path):\n","        print(\"No existing results file found. Starting fresh.\")\n","        return []\n","\n","    try:\n","        with open(json_path, 'r', encoding='utf-8') as f:\n","            results = json.load(f)\n","            print(f\"Loaded {len(results)} existing results from '{json_path}'.\")\n","            return results\n","    except (json.JSONDecodeError, Exception) as e:\n","        print(f\"Error loading '{json_path}': {e}. Starting with a new list.\")\n","        # If file is corrupt, start fresh to avoid losing data\n","        return []\n","\n","def get_start_index(progress_file):\n","    \"\"\"Reads the progress file to find where to resume.\"\"\"\n","    if not os.path.exists(progress_file):\n","        print(\"No progress file found. Starting from index 0.\")\n","        return 0\n","\n","    try:\n","        with open(progress_file, 'r') as f:\n","            start_index = int(f.read().strip())\n","            print(f\"Resuming analysis from index {start_index}.\")\n","            return start_index\n","    except Exception as e:\n","        print(f\"Error reading progress file '{progress_file}': {e}. Starting from 0.\")\n","        return 0\n","\n","def save_progress(progress_file, index):\n","    \"\"\"Saves the index of the *next* email to process.\"\"\"\n","    try:\n","        with open(progress_file, 'w') as f:\n","            f.write(str(index))\n","        print(f\"Progress saved: Next run will start at index {index}.\")\n","    except Exception as e:\n","        print(f\"Error saving progress to '{progress_file}': {e}\")\n","\n","def save_final_results(all_results, output_json_path):\n","    \"\"\"Saves the final, complete list of results to the JSON file.\"\"\"\n","    if not all_results:\n","        print(\"No results to save.\")\n","        return\n","\n","    print(f\"\\nSaving {len(all_results)} total results to '{output_json_path}'...\")\n","\n","    # We *overwrite* the file with the full, updated list\n","    # This ensures the JSON is always valid\n","    try:\n","        with open(output_json_path, 'w', encoding='utf-8') as f:\n","            json.dump(all_results, f, indent=4, ensure_ascii=False)\n","        print(f\"Successfully saved all results to '{output_json_path}'\")\n","    except Exception as e:\n","        print(f\"Error saving to JSON file: {e}\")\n","\n","def process_emails(input_json_path, output_json_path, progress_file, limit=None):\n","    \"\"\"\n","    Reads a JSON file of emails, processes each one, and handles graceful saving.\n","    \"\"\"\n","    print(f\"Starting to process '{input_json_path}'...\")\n","\n","    try:\n","        with open(input_json_path, 'r', encoding='utf-8') as f:\n","            all_emails = json.load(f)\n","    except FileNotFoundError:\n","        print(f\"Error: The file '{input_json_path}' was not found.\")\n","        print(\"Please make sure 'clinton_emails.json' is uploaded to your Colab environment.\")\n","        return\n","    except json.JSONDecodeError:\n","        print(f\"Error: Could not decode JSON from '{input_json_path}'.\")\n","        return\n","\n","    # --- Resume Logic ---\n","    all_results = load_existing_results(output_json_path)\n","    start_index = get_start_index(progress_file)\n","\n","    # This tracks the index of the last *successful* analysis in this run\n","    last_successful_index = -1\n","\n","    # --- Slice emails to process ---\n","    # Apply sample limit *first* if it exists\n","    total_emails_to_process = all_emails\n","    if limit is not None:\n","        # Ensure limit doesn't go out of bounds, especially with start_index\n","        end_limit = min(start_index + limit, len(all_emails))\n","        total_emails_to_process = all_emails[:end_limit]\n","        print(f\"--- SAMPLE MODE: Processing a max of {limit} emails, starting from {start_index}. ---\")\n","\n","    # Now, get the actual slice of emails we need to work on\n","    emails_to_process_slice = total_emails_to_process[start_index:]\n","\n","    if not emails_to_process_slice:\n","        print(\"No new emails to process. All analysis may be complete.\")\n","\n","    try:\n","        # Use enumerate(start=start_index) to get the *correct global index*\n","        for global_index, email_obj in enumerate(total_emails_to_process[start_index:], start=start_index):\n","\n","            print(f\"\\nProcessing email (Global Index {global_index}) of {len(all_emails)}...\")\n","\n","            analysis_result = analyze_single_email(email_obj)\n","\n","            if analysis_result:\n","                all_results.append(analysis_result)\n","                # We record the *global index* of the last success\n","                last_successful_index = global_index\n","\n","            time.sleep(1)\n","\n","    except KeyboardInterrupt:\n","        print(\"\\n=\"*50)\n","        print(\"STOP command (Ctrl+C) received.\")\n","        print(\"Terminating analysis and saving results/progress...\")\n","        print(\"=\"*50)\n","    except Exception as e:\n","        print(\"\\n=\"*50)\n","        print(f\"An unexpected error occurred: {e}\")\n","        print(\"This may be an API token limit or quota issue.\")\n","        print(\"Terminating analysis and saving partial results/progress...\")\n","        print(\"=\"*50)\n","\n","    finally:\n","        # --- Save Progress ---\n","        if last_successful_index != -1:\n","            # If we successfully processed email at index `X`,\n","            # the *next* run should start at index `X + 1`.\n","            next_index_to_process = last_successful_index + 1\n","            save_progress(progress_file, next_index_to_process)\n","        else:\n","            print(\"No new emails were successfully processed in this run. Progress file not updated.\")\n","\n","        # --- Save Full Results ---\n","        # This saves the combined list of (old + new) results\n","        save_final_results(all_results, output_json_path)\n","        print(\"Analysis finished.\")\n","\n","# --- How to run the script ---\n","if __name__ == \"__main__\":\n","\n","    # --- 1. CONFIGURE AND TEST API ---\n","    # This will exit if the key is missing or the test prompt fails.\n","    configure_api_and_test()\n","\n","    # --- 2. SET FILEPATHS AND LIMIT ---\n","    # Filepaths are defined at the top of the script\n","\n","    # Set SAMPLE_LIMIT to 3 to test the first 3 emails (from the start_index)\n","    # Set SAMPLE_LIMIT to None to process all emails in the file (from the start_index)\n","    SAMPLE_LIMIT = None\n","\n","    # --- 3. RUN ANALYSIS ---\n","    process_emails(\n","        input_json_path=INPUT_FILE,\n","        output_json_path=OUTPUT_JSON_FILE,\n","        progress_file=PROGRESS_FILE,\n","        limit=SAMPLE_LIMIT\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"X-2rmi1X0UPl","executionInfo":{"status":"ok","timestamp":1763047236233,"user_tz":300,"elapsed":6359,"user":{"displayName":"Nitya Mittal","userId":"11940585067481762741"}},"outputId":"411de184-c384-4bad-c1aa-df47bc1a7757"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded API key from Colab Secrets.\n","Starting to process 'clinton_emails.json'...\n","Loaded 1004 existing results from 'clinton_analysis_results.json'.\n","Resuming analysis from index 1093.\n","\n","Processing email (Global Index 1093) of 2050...\n","  > Analyzing email_id: 17336...\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:tornado.access:503 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 1668.63ms\n","ERROR:tornado.access:503 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 2808.25ms\n"]},{"output_type":"stream","name":"stdout","text":["\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","=\n","STOP command (Ctrl+C) received.\n","Terminating analysis and saving results/progress...\n","==================================================\n","No new emails were successfully processed in this run. Progress file not updated.\n","\n","Saving 1004 total results to 'clinton_analysis_results.json'...\n","Successfully saved all results to 'clinton_analysis_results.json'\n","Analysis finished.\n"]}]}]}